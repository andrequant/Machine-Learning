{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMqsu+AF4I+NkSJpeMzW5DO",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/andrequant/Machine-Learning/blob/main/Reinforcement-Learning/Deep_RL_Nicholas_Renotte.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Código para acompanhar o vídeo:\n",
        "\n",
        "https://www.youtube.com/watch?v=cO5g5qLrLSo&t=1s"
      ],
      "metadata": {
        "id": "Dh4XSkX2VJqe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install gym[classic_control]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yFpzszQMiE-a",
        "outputId": "ff5147e1-f92e-40dc-984e-103b23e43080"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: gym[classic_control] in /usr/local/lib/python3.9/dist-packages (0.25.2)\n",
            "Requirement already satisfied: importlib-metadata>=4.8.0 in /usr/local/lib/python3.9/dist-packages (from gym[classic_control]) (6.0.0)\n",
            "Requirement already satisfied: numpy>=1.18.0 in /usr/local/lib/python3.9/dist-packages (from gym[classic_control]) (1.22.4)\n",
            "Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.9/dist-packages (from gym[classic_control]) (2.2.1)\n",
            "Requirement already satisfied: gym-notices>=0.0.4 in /usr/local/lib/python3.9/dist-packages (from gym[classic_control]) (0.0.8)\n",
            "Collecting pygame==2.1.0\n",
            "  Downloading pygame-2.1.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.3/18.3 MB\u001b[0m \u001b[31m41.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.9/dist-packages (from importlib-metadata>=4.8.0->gym[classic_control]) (3.15.0)\n",
            "Installing collected packages: pygame\n",
            "Successfully installed pygame-2.1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install keras-rl2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "66Ig-PG_nopl",
        "outputId": "9cff70be-c0f1-40c7-8905-ab5d3ef134a0"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting keras-rl2\n",
            "  Downloading keras_rl2-1.0.5-py3-none-any.whl (52 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m52.1/52.1 KB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tensorflow in /usr/local/lib/python3.9/dist-packages (from keras-rl2) (2.11.0)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.9/dist-packages (from tensorflow->keras-rl2) (0.31.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow->keras-rl2) (1.4.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow->keras-rl2) (3.1.0)\n",
            "Requirement already satisfied: flatbuffers>=2.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow->keras-rl2) (23.3.3)\n",
            "Requirement already satisfied: tensorflow-estimator<2.12,>=2.11.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow->keras-rl2) (2.11.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.9/dist-packages (from tensorflow->keras-rl2) (4.5.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow->keras-rl2) (2.2.0)\n",
            "Requirement already satisfied: keras<2.12,>=2.11.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow->keras-rl2) (2.11.0)\n",
            "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /usr/local/lib/python3.9/dist-packages (from tensorflow->keras-rl2) (0.4.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.9/dist-packages (from tensorflow->keras-rl2) (57.4.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.9/dist-packages (from tensorflow->keras-rl2) (3.3.0)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.9/dist-packages (from tensorflow->keras-rl2) (1.22.4)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow->keras-rl2) (15.0.6.1)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.9/dist-packages (from tensorflow->keras-rl2) (1.51.3)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.9/dist-packages (from tensorflow->keras-rl2) (0.2.0)\n",
            "Requirement already satisfied: protobuf<3.20,>=3.9.2 in /usr/local/lib/python3.9/dist-packages (from tensorflow->keras-rl2) (3.19.6)\n",
            "Requirement already satisfied: tensorboard<2.12,>=2.11 in /usr/local/lib/python3.9/dist-packages (from tensorflow->keras-rl2) (2.11.2)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow->keras-rl2) (1.15.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow->keras-rl2) (1.6.3)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.9/dist-packages (from tensorflow->keras-rl2) (23.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow->keras-rl2) (1.15.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.9/dist-packages (from astunparse>=1.6.0->tensorflow->keras-rl2) (0.38.4)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.9/dist-packages (from tensorboard<2.12,>=2.11->tensorflow->keras-rl2) (2.25.1)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.9/dist-packages (from tensorboard<2.12,>=2.11->tensorflow->keras-rl2) (1.8.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.9/dist-packages (from tensorboard<2.12,>=2.11->tensorflow->keras-rl2) (3.4.1)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.9/dist-packages (from tensorboard<2.12,>=2.11->tensorflow->keras-rl2) (2.2.3)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.9/dist-packages (from tensorboard<2.12,>=2.11->tensorflow->keras-rl2) (0.4.6)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.9/dist-packages (from tensorboard<2.12,>=2.11->tensorflow->keras-rl2) (0.6.1)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.9/dist-packages (from tensorboard<2.12,>=2.11->tensorflow->keras-rl2) (2.16.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.9/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow->keras-rl2) (0.2.8)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.9/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow->keras-rl2) (5.3.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.9/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow->keras-rl2) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.9/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.12,>=2.11->tensorflow->keras-rl2) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.9/dist-packages (from markdown>=2.6.8->tensorboard<2.12,>=2.11->tensorflow->keras-rl2) (6.0.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow->keras-rl2) (1.26.14)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.9/dist-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow->keras-rl2) (4.0.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow->keras-rl2) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow->keras-rl2) (2022.12.7)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.9/dist-packages (from werkzeug>=1.0.1->tensorboard<2.12,>=2.11->tensorflow->keras-rl2) (2.1.2)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.9/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.12,>=2.11->tensorflow->keras-rl2) (3.15.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.9/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow->keras-rl2) (0.4.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.9/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.12,>=2.11->tensorflow->keras-rl2) (3.2.2)\n",
            "Installing collected packages: keras-rl2\n",
            "Successfully installed keras-rl2-1.0.5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Colab cannot run env.render(). This is just a work around to check is running in colab.\n",
        "## And use a dummy video display.\n",
        "\n",
        "try:\n",
        "  import google.colab\n",
        "  import os\n",
        "  os.environ['SDL_VIDEODRIVER']='dummy'\n",
        "  import pygame\n",
        "  pygame.display.set_mode((640,480))\n",
        "\n",
        "except:\n",
        "  pass"
      ],
      "metadata": {
        "id": "b0rasgBAi6HN"
      },
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 79,
      "metadata": {
        "id": "qSN_2KYfVCFy"
      },
      "outputs": [],
      "source": [
        "import gym\n",
        "import random\n",
        "import tensorflow as tf"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#1. Test a Random Environment with OpenAI Gym"
      ],
      "metadata": {
        "id": "n944Dh7GVqr2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "env = gym.make('CartPole-v0')\n",
        "states = env.observation_space.shape[0]\n",
        "actions = env.action_space.n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "56wR6J9xVUEL",
        "outputId": "8e90e829-827d-4a45-9156-43e844766686"
      },
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/gym/envs/registration.py:593: UserWarning: \u001b[33mWARN: The environment CartPole-v0 is out of date. You should consider upgrading to version `v1`.\u001b[0m\n",
            "  logger.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "actions"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3es5qkylVpKf",
        "outputId": "01499737-92a8-49bf-fefe-eec6fcbe288b"
      },
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2"
            ]
          },
          "metadata": {},
          "execution_count": 81
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "episodes = 10\n",
        "for episode in range(1, episodes+1):\n",
        "  state = env.reset()\n",
        "  done = False\n",
        "  score = 0\n",
        "\n",
        "  while not done:\n",
        "    env.render()\n",
        "    action = random.choice([0,1])\n",
        "    n_state, reward, done, info = env.step(action)\n",
        "    score += reward\n",
        "  print('Episode:{} Score:{}'.format(episode, score))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tj3_jfiiVxba",
        "outputId": "82eb4155-9769-4902-af91-a1ae2fb88139"
      },
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode:1 Score:15.0\n",
            "Episode:2 Score:23.0\n",
            "Episode:3 Score:13.0\n",
            "Episode:4 Score:22.0\n",
            "Episode:5 Score:11.0\n",
            "Episode:6 Score:14.0\n",
            "Episode:7 Score:10.0\n",
            "Episode:8 Score:13.0\n",
            "Episode:9 Score:21.0\n",
            "Episode:10 Score:72.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#2. Create a Deep Learning Model with Keras"
      ],
      "metadata": {
        "id": "h6j2HFTQV0w5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Flatten\n",
        "from  tensorflow.keras.optimizers import Adam"
      ],
      "metadata": {
        "id": "JWXk4u_dWQtX"
      },
      "execution_count": 83,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def build_model(states, actions):\n",
        "  model = Sequential()\n",
        "  model.add(Flatten(input_shape=(1, states)))\n",
        "  model.add(Dense(24, activation='relu'))\n",
        "  model.add(Dense(24, activation='relu'))\n",
        "  model.add(Dense(actions, activation='linear'))\n",
        "  return model"
      ],
      "metadata": {
        "id": "FgX1JvhPmKoN"
      },
      "execution_count": 84,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "del model"
      ],
      "metadata": {
        "id": "3dTvUdvXr7i2"
      },
      "execution_count": 85,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = build_model(states, actions)"
      ],
      "metadata": {
        "id": "9n4Z1U--mKwm"
      },
      "execution_count": 86,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7XK0OeB5mK1G",
        "outputId": "ab063c65-7976-4b47-b1d5-bfa634210d05"
      },
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " flatten_3 (Flatten)         (None, 4)                 0         \n",
            "                                                                 \n",
            " dense_9 (Dense)             (None, 24)                120       \n",
            "                                                                 \n",
            " dense_10 (Dense)            (None, 24)                600       \n",
            "                                                                 \n",
            " dense_11 (Dense)            (None, 2)                 50        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 770\n",
            "Trainable params: 770\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3. Build Agent with Keras-RL"
      ],
      "metadata": {
        "id": "1aU7EwS_nRN5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from rl.agents import DQNAgent\n",
        "from rl.policy import BoltzmannQPolicy\n",
        "from rl.memory import SequentialMemory"
      ],
      "metadata": {
        "id": "O8_GPTHYmK4s"
      },
      "execution_count": 88,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def build_agent(model, actions):\n",
        "  policy = BoltzmannQPolicy()\n",
        "  memory = SequentialMemory(limit=5000, window_length=1)\n",
        "  dqn = DQNAgent(model=model, memory=memory, policy=policy,\n",
        "                 nb_actions=actions, nb_steps_warmup=10, target_model_update=1e-2)\n",
        "  \n",
        "  return dqn"
      ],
      "metadata": {
        "id": "mwNT6Nbqn4FQ"
      },
      "execution_count": 89,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\", category=DeprecationWarning) "
      ],
      "metadata": {
        "id": "MkPB78tXsdgx"
      },
      "execution_count": 90,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dqn = build_agent(model, actions)\n",
        "dqn.compile(tf.keras.optimizers.legacy.Adam(learning_rate=1e-3), metrics=['mae'])\n",
        "dqn.fit(env, nb_steps=5000, visualize=False, verbose=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JARuk3jjn4jd",
        "outputId": "3c6e0cae-0cda-4d27-ded6-b9721ecf7820"
      },
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training for 5000 steps ...\n",
            "Interval 1 (0 steps performed)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/keras/engine/training_v1.py:2357: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
            "  updates=self.state_updates,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r    1/10000 [..............................] - ETA: 1:44:40 - reward: 1.0000"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/rl/memory.py:37: UserWarning: Not enough entries to sample without replacement. Consider increasing your warm-up phase to avoid oversampling!\n",
            "  warnings.warn('Not enough entries to sample without replacement. Consider increasing your warm-up phase to avoid oversampling!')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 4997/10000 [=============>................] - ETA: 47s - reward: 1.0000done, took 48.143 seconds\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f9414bc5520>"
            ]
          },
          "metadata": {},
          "execution_count": 91
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "scores = dqn.test(env, nb_episodes=100, visualize=False)\n",
        "print(np.mean(scores.history['episode_reward']))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DP629-5fn4hI",
        "outputId": "3dc1088d-4b07-4b70-eb51-83a9c0dba5ac"
      },
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Testing for 100 episodes ...\n",
            "Episode 1: reward: 200.000, steps: 200\n",
            "Episode 2: reward: 200.000, steps: 200\n",
            "Episode 3: reward: 200.000, steps: 200\n",
            "Episode 4: reward: 200.000, steps: 200\n",
            "Episode 5: reward: 200.000, steps: 200\n",
            "Episode 6: reward: 200.000, steps: 200\n",
            "Episode 7: reward: 200.000, steps: 200\n",
            "Episode 8: reward: 200.000, steps: 200\n",
            "Episode 9: reward: 200.000, steps: 200\n",
            "Episode 10: reward: 200.000, steps: 200\n",
            "Episode 11: reward: 200.000, steps: 200\n",
            "Episode 12: reward: 200.000, steps: 200\n",
            "Episode 13: reward: 200.000, steps: 200\n",
            "Episode 14: reward: 200.000, steps: 200\n",
            "Episode 15: reward: 200.000, steps: 200\n",
            "Episode 16: reward: 200.000, steps: 200\n",
            "Episode 17: reward: 200.000, steps: 200\n",
            "Episode 18: reward: 200.000, steps: 200\n",
            "Episode 19: reward: 200.000, steps: 200\n",
            "Episode 20: reward: 200.000, steps: 200\n",
            "Episode 21: reward: 200.000, steps: 200\n",
            "Episode 22: reward: 200.000, steps: 200\n",
            "Episode 23: reward: 200.000, steps: 200\n",
            "Episode 24: reward: 200.000, steps: 200\n",
            "Episode 25: reward: 200.000, steps: 200\n",
            "Episode 26: reward: 200.000, steps: 200\n",
            "Episode 27: reward: 200.000, steps: 200\n",
            "Episode 28: reward: 200.000, steps: 200\n",
            "Episode 29: reward: 200.000, steps: 200\n",
            "Episode 30: reward: 200.000, steps: 200\n",
            "Episode 31: reward: 200.000, steps: 200\n",
            "Episode 32: reward: 200.000, steps: 200\n",
            "Episode 33: reward: 200.000, steps: 200\n",
            "Episode 34: reward: 200.000, steps: 200\n",
            "Episode 35: reward: 200.000, steps: 200\n",
            "Episode 36: reward: 200.000, steps: 200\n",
            "Episode 37: reward: 200.000, steps: 200\n",
            "Episode 38: reward: 200.000, steps: 200\n",
            "Episode 39: reward: 200.000, steps: 200\n",
            "Episode 40: reward: 200.000, steps: 200\n",
            "Episode 41: reward: 200.000, steps: 200\n",
            "Episode 42: reward: 200.000, steps: 200\n",
            "Episode 43: reward: 200.000, steps: 200\n",
            "Episode 44: reward: 200.000, steps: 200\n",
            "Episode 45: reward: 200.000, steps: 200\n",
            "Episode 46: reward: 200.000, steps: 200\n",
            "Episode 47: reward: 200.000, steps: 200\n",
            "Episode 48: reward: 200.000, steps: 200\n",
            "Episode 49: reward: 200.000, steps: 200\n",
            "Episode 50: reward: 200.000, steps: 200\n",
            "Episode 51: reward: 200.000, steps: 200\n",
            "Episode 52: reward: 200.000, steps: 200\n",
            "Episode 53: reward: 200.000, steps: 200\n",
            "Episode 54: reward: 200.000, steps: 200\n",
            "Episode 55: reward: 200.000, steps: 200\n",
            "Episode 56: reward: 200.000, steps: 200\n",
            "Episode 57: reward: 200.000, steps: 200\n",
            "Episode 58: reward: 200.000, steps: 200\n",
            "Episode 59: reward: 200.000, steps: 200\n",
            "Episode 60: reward: 200.000, steps: 200\n",
            "Episode 61: reward: 200.000, steps: 200\n",
            "Episode 62: reward: 200.000, steps: 200\n",
            "Episode 63: reward: 200.000, steps: 200\n",
            "Episode 64: reward: 200.000, steps: 200\n",
            "Episode 65: reward: 200.000, steps: 200\n",
            "Episode 66: reward: 200.000, steps: 200\n",
            "Episode 67: reward: 200.000, steps: 200\n",
            "Episode 68: reward: 200.000, steps: 200\n",
            "Episode 69: reward: 200.000, steps: 200\n",
            "Episode 70: reward: 200.000, steps: 200\n",
            "Episode 71: reward: 200.000, steps: 200\n",
            "Episode 72: reward: 200.000, steps: 200\n",
            "Episode 73: reward: 200.000, steps: 200\n",
            "Episode 74: reward: 200.000, steps: 200\n",
            "Episode 75: reward: 200.000, steps: 200\n",
            "Episode 76: reward: 200.000, steps: 200\n",
            "Episode 77: reward: 200.000, steps: 200\n",
            "Episode 78: reward: 200.000, steps: 200\n",
            "Episode 79: reward: 200.000, steps: 200\n",
            "Episode 80: reward: 200.000, steps: 200\n",
            "Episode 81: reward: 200.000, steps: 200\n",
            "Episode 82: reward: 200.000, steps: 200\n",
            "Episode 83: reward: 200.000, steps: 200\n",
            "Episode 84: reward: 200.000, steps: 200\n",
            "Episode 85: reward: 200.000, steps: 200\n",
            "Episode 86: reward: 200.000, steps: 200\n",
            "Episode 87: reward: 200.000, steps: 200\n",
            "Episode 88: reward: 200.000, steps: 200\n",
            "Episode 89: reward: 200.000, steps: 200\n",
            "Episode 90: reward: 200.000, steps: 200\n",
            "Episode 91: reward: 200.000, steps: 200\n",
            "Episode 92: reward: 200.000, steps: 200\n",
            "Episode 93: reward: 200.000, steps: 200\n",
            "Episode 94: reward: 200.000, steps: 200\n",
            "Episode 95: reward: 200.000, steps: 200\n",
            "Episode 96: reward: 200.000, steps: 200\n",
            "Episode 97: reward: 200.000, steps: 200\n",
            "Episode 98: reward: 200.000, steps: 200\n",
            "Episode 99: reward: 200.000, steps: 200\n",
            "Episode 100: reward: 200.000, steps: 200\n",
            "200.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4. Reloading Agent from Memory"
      ],
      "metadata": {
        "id": "OXZYTA5RuBGf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dqn.save_weights('dqn_weights.h5f',overwrite=True)"
      ],
      "metadata": {
        "id": "xyYqhaC3n4bW"
      },
      "execution_count": 93,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "del model\n",
        "del dqn\n",
        "del env"
      ],
      "metadata": {
        "id": "mrgsNKcKn4Mn"
      },
      "execution_count": 94,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "env = gym.make('CartPole-v0')\n",
        "actions = env.action_space.n\n",
        "states = env.observation_space.shape[0]\n",
        "model = build_model(states, actions)\n",
        "dqn = build_agent(model, actions)\n",
        "dqn.compile(tf.keras.optimizers.legacy.Adam(learning_rate=1e-3), metrics=['mae'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J07fXAykmK72",
        "outputId": "d0197d55-ff02-450f-d51a-52e3523e0a6e"
      },
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/gym/envs/registration.py:593: UserWarning: \u001b[33mWARN: The environment CartPole-v0 is out of date. You should consider upgrading to version `v1`.\u001b[0m\n",
            "  logger.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dqn.load_weights('dqn_weights.h5f')"
      ],
      "metadata": {
        "id": "1N9Q0FZLvBYZ"
      },
      "execution_count": 96,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "scores = dqn.test(env, nb_episodes=100, visualize=False)\n",
        "print(np.mean(scores.history['episode_reward']))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xFPNA7CUvU1Y",
        "outputId": "a1a18ae4-d488-4a9f-d1c9-1c75a0760c21"
      },
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Testing for 100 episodes ...\n",
            "Episode 1: reward: 200.000, steps: 200\n",
            "Episode 2: reward: 200.000, steps: 200\n",
            "Episode 3: reward: 200.000, steps: 200\n",
            "Episode 4: reward: 200.000, steps: 200\n",
            "Episode 5: reward: 200.000, steps: 200\n",
            "Episode 6: reward: 200.000, steps: 200\n",
            "Episode 7: reward: 200.000, steps: 200\n",
            "Episode 8: reward: 200.000, steps: 200\n",
            "Episode 9: reward: 200.000, steps: 200\n",
            "Episode 10: reward: 200.000, steps: 200\n",
            "Episode 11: reward: 200.000, steps: 200\n",
            "Episode 12: reward: 200.000, steps: 200\n",
            "Episode 13: reward: 200.000, steps: 200\n",
            "Episode 14: reward: 200.000, steps: 200\n",
            "Episode 15: reward: 200.000, steps: 200\n",
            "Episode 16: reward: 200.000, steps: 200\n",
            "Episode 17: reward: 200.000, steps: 200\n",
            "Episode 18: reward: 200.000, steps: 200\n",
            "Episode 19: reward: 200.000, steps: 200\n",
            "Episode 20: reward: 200.000, steps: 200\n",
            "Episode 21: reward: 200.000, steps: 200\n",
            "Episode 22: reward: 200.000, steps: 200\n",
            "Episode 23: reward: 200.000, steps: 200\n",
            "Episode 24: reward: 200.000, steps: 200\n",
            "Episode 25: reward: 200.000, steps: 200\n",
            "Episode 26: reward: 200.000, steps: 200\n",
            "Episode 27: reward: 200.000, steps: 200\n",
            "Episode 28: reward: 200.000, steps: 200\n",
            "Episode 29: reward: 200.000, steps: 200\n",
            "Episode 30: reward: 200.000, steps: 200\n",
            "Episode 31: reward: 200.000, steps: 200\n",
            "Episode 32: reward: 200.000, steps: 200\n",
            "Episode 33: reward: 200.000, steps: 200\n",
            "Episode 34: reward: 200.000, steps: 200\n",
            "Episode 35: reward: 200.000, steps: 200\n",
            "Episode 36: reward: 200.000, steps: 200\n",
            "Episode 37: reward: 200.000, steps: 200\n",
            "Episode 38: reward: 200.000, steps: 200\n",
            "Episode 39: reward: 200.000, steps: 200\n",
            "Episode 40: reward: 200.000, steps: 200\n",
            "Episode 41: reward: 200.000, steps: 200\n",
            "Episode 42: reward: 200.000, steps: 200\n",
            "Episode 43: reward: 200.000, steps: 200\n",
            "Episode 44: reward: 200.000, steps: 200\n",
            "Episode 45: reward: 200.000, steps: 200\n",
            "Episode 46: reward: 200.000, steps: 200\n",
            "Episode 47: reward: 200.000, steps: 200\n",
            "Episode 48: reward: 200.000, steps: 200\n",
            "Episode 49: reward: 200.000, steps: 200\n",
            "Episode 50: reward: 200.000, steps: 200\n",
            "Episode 51: reward: 200.000, steps: 200\n",
            "Episode 52: reward: 200.000, steps: 200\n",
            "Episode 53: reward: 200.000, steps: 200\n",
            "Episode 54: reward: 200.000, steps: 200\n",
            "Episode 55: reward: 200.000, steps: 200\n",
            "Episode 56: reward: 200.000, steps: 200\n",
            "Episode 57: reward: 200.000, steps: 200\n",
            "Episode 58: reward: 200.000, steps: 200\n",
            "Episode 59: reward: 200.000, steps: 200\n",
            "Episode 60: reward: 200.000, steps: 200\n",
            "Episode 61: reward: 200.000, steps: 200\n",
            "Episode 62: reward: 200.000, steps: 200\n",
            "Episode 63: reward: 200.000, steps: 200\n",
            "Episode 64: reward: 200.000, steps: 200\n",
            "Episode 65: reward: 200.000, steps: 200\n",
            "Episode 66: reward: 200.000, steps: 200\n",
            "Episode 67: reward: 200.000, steps: 200\n",
            "Episode 68: reward: 200.000, steps: 200\n",
            "Episode 69: reward: 200.000, steps: 200\n",
            "Episode 70: reward: 200.000, steps: 200\n",
            "Episode 71: reward: 200.000, steps: 200\n",
            "Episode 72: reward: 200.000, steps: 200\n",
            "Episode 73: reward: 200.000, steps: 200\n",
            "Episode 74: reward: 200.000, steps: 200\n",
            "Episode 75: reward: 200.000, steps: 200\n",
            "Episode 76: reward: 200.000, steps: 200\n",
            "Episode 77: reward: 200.000, steps: 200\n",
            "Episode 78: reward: 200.000, steps: 200\n",
            "Episode 79: reward: 200.000, steps: 200\n",
            "Episode 80: reward: 200.000, steps: 200\n",
            "Episode 81: reward: 200.000, steps: 200\n",
            "Episode 82: reward: 200.000, steps: 200\n",
            "Episode 83: reward: 200.000, steps: 200\n",
            "Episode 84: reward: 200.000, steps: 200\n",
            "Episode 85: reward: 200.000, steps: 200\n",
            "Episode 86: reward: 200.000, steps: 200\n",
            "Episode 87: reward: 200.000, steps: 200\n",
            "Episode 88: reward: 200.000, steps: 200\n",
            "Episode 89: reward: 200.000, steps: 200\n",
            "Episode 90: reward: 200.000, steps: 200\n",
            "Episode 91: reward: 200.000, steps: 200\n",
            "Episode 92: reward: 200.000, steps: 200\n",
            "Episode 93: reward: 200.000, steps: 200\n",
            "Episode 94: reward: 200.000, steps: 200\n",
            "Episode 95: reward: 200.000, steps: 200\n",
            "Episode 96: reward: 200.000, steps: 200\n",
            "Episode 97: reward: 200.000, steps: 200\n",
            "Episode 98: reward: 200.000, steps: 200\n",
            "Episode 99: reward: 200.000, steps: 200\n",
            "Episode 100: reward: 200.000, steps: 200\n",
            "200.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "LnWTmk9rv5wb"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}